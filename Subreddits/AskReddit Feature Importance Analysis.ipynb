{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AskReddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddit = 'AskReddit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts import Munger as mg\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_importance(train, test, features, predict, trees=10, state=None):\n",
    "    \n",
    "    X = train[features]\n",
    "    y = train[predict]\n",
    "\n",
    "    # Build a forest and compute the feature importances\n",
    "    forest = ExtraTreesClassifier(n_estimators=trees,\n",
    "                                  random_state=state)\n",
    "\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print '%d.' % (f + 1), X.columns.values[indices[f]], '(%f)' % importances[indices[f]]\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), [ X.columns.values[i] for i in indices], rotation=75)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "    X = test[features]\n",
    "    y = test[predict]\n",
    "\n",
    "    print 'Score:', forest.score(X,y)\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_vectorize(train, test, maxdf=0.8, mindf=0.05):\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_df=maxdf, min_df=mindf)\n",
    "\n",
    "    train_tfidf = tfidf.fit_transform(train)\n",
    "    test_tfidf = tfidf.transform(test)\n",
    "    \n",
    "    return {'train_tfidf': train_tfidf,'test_tfidf': test_tfidf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "def cluster(train, test, clusters=10, iterations=300, init=10):\n",
    "    km = KMeans(n_clusters=clusters, init='k-means++', max_iter=iterations, n_init=init)\n",
    "    \n",
    "    train_preds = km.fit_predict(train)\n",
    "    test_preds = km.predict(test)\n",
    "    \n",
    "    return {'train_preds': train_preds, 'test_preds': test_preds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_feature_importance(train_filename, test_filename, features, predict):\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(train_filename)\n",
    "    test = pd.read_csv(test_filename)\n",
    "    \n",
    "    \n",
    "    train = train.append(test.head(350))\n",
    "    test = test.tail(50)\n",
    "    \n",
    "    # Munge data\n",
    "    train = mg.munge_dataset(train)\n",
    "    test = mg.munge_dataset(test)\n",
    "    \n",
    "    if 'watson cluster' in features:\n",
    "        # Create Watson Vector\n",
    "        watson = ['Watson Anger', 'Watson Disgust', 'Watson Fear',\n",
    "                   'Watson Joy', 'Watson Sadness', 'Watson Analytical',\n",
    "                   'Watson Confident', 'Watson Tenative', 'Watson Openness',\n",
    "                   'Watson Conscientiousness', 'Watson Extraversion',\n",
    "                   'Watson Agreeableness', 'Watson Emotional Range'] \n",
    "        train_watson_vector = train[watson].values\n",
    "        test_watson_vector = test[watson].values\n",
    "\n",
    "        # Cluster by Watson Vector\n",
    "        preds = cluster(train_watson_vector, test_watson_vector, 12, 300, 10)\n",
    "        train['watson cluster'] = preds['train_preds']\n",
    "        test['watson cluster'] = preds['test_preds']\n",
    "\n",
    "    if 'body cluster' in features:\n",
    "        # Create TFIDF vector for body\n",
    "        tfidf = tfidf_vectorize(train['body'], test['body'], maxdf=0.8, mindf=0.05)\n",
    "        train_tfidf = tfidf['train_tfidf']\n",
    "        test_tfidf = tfidf['test_tfidf']\n",
    "        \n",
    "        # Cluster by Body TFIDF Vector\n",
    "        preds = cluster(train_tfidf, test_tfidf, 35, 300, 10)\n",
    "\n",
    "        train['body cluster'] = preds['train_preds']\n",
    "        test['body cluster'] = preds['test_preds']\n",
    "\n",
    "    # Map gilded to boolean\n",
    "    train['gilded'] = train['gilded'].astype(bool)\n",
    "    test['gilded'] = test['gilded'].astype(bool)\n",
    "    \n",
    "    # Print feature importance\n",
    "    return feature_importance(train, test, features, predict, trees=250, state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Bracket\n",
      "Word Count\n",
      "Time of Day\n",
      "watson cluster\n",
      "body cluster\n",
      "Grammer Errors\n",
      "Sentiment Negative\n",
      "Sentiment Positive\n",
      "Sentiment Neutral\n",
      "Watson Anger\n",
      "Watson Disgust\n",
      "Watson Fear\n",
      "Watson Joy\n",
      "Watson Sadness\n",
      "Watson Tenative\n",
      "Watson Openness\n",
      "Watson Conscientiousness\n",
      "Watson Extraversion\n",
      "Watson Agreeableness\n",
      "Watson Emotional Range\n",
      "\n",
      "Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('./mytrain/added' + subreddit + '_train.csv')\n",
    "test = pd.read_csv('./mytest/added' + subreddit + '_test.csv')\n",
    "\n",
    "train = train.append(test.head(350))\n",
    "test = test.tail(50)\n",
    "\n",
    "train = mg.munge_dataset(train)\n",
    "test = mg.munge_dataset(test)\n",
    "\n",
    "# Create Watson Vector\n",
    "watson = ['Watson Anger', 'Watson Disgust', 'Watson Fear',\n",
    "           'Watson Joy', 'Watson Sadness', 'Watson Analytical',\n",
    "           'Watson Confident', 'Watson Tenative', 'Watson Openness',\n",
    "           'Watson Conscientiousness', 'Watson Extraversion',\n",
    "           'Watson Agreeableness', 'Watson Emotional Range'] \n",
    "train_watson_vector = train[watson].values\n",
    "test_watson_vector = test[watson].values\n",
    "\n",
    "# Cluster by Watson Vector\n",
    "preds = cluster(train_watson_vector, test_watson_vector, 12, 300, 10)\n",
    "train['watson cluster'] = preds['train_preds']\n",
    "test['watson cluster'] = preds['test_preds']\n",
    "\n",
    "# Create TFIDF vector for body\n",
    "tfidf = tfidf_vectorize(train['body'], test['body'], maxdf=0.8, mindf=0.05)\n",
    "train_tfidf = tfidf['train_tfidf']\n",
    "test_tfidf = tfidf['test_tfidf']\n",
    "\n",
    "# Cluster by Body TFIDF Vector\n",
    "preds = cluster(train_tfidf, test_tfidf, 35, 300, 10)\n",
    "\n",
    "train['body cluster'] = preds['train_preds']\n",
    "test['body cluster'] = preds['test_preds']\n",
    "\n",
    "features = [\n",
    "    'Score Bracket', \n",
    "    'Contains MD', \n",
    "    'Word Count', \n",
    "    'Time of Day', \n",
    "    'watson cluster',\n",
    "    'body cluster',\n",
    "    'Grammer Errors',\n",
    "    'Sentiment Label',\n",
    "    'Sentiment Negative',\n",
    "    'Sentiment Positive',\n",
    "    'Sentiment Neutral',\n",
    "    'flair',\n",
    "    'Watson Anger', \n",
    "    'Watson Disgust', \n",
    "    'Watson Fear',\n",
    "    'Watson Joy', \n",
    "    'Watson Sadness', \n",
    "    'Watson Analytical',\n",
    "    'Watson Confident', \n",
    "    'Watson Tenative', \n",
    "    'Watson Openness',\n",
    "    'Watson Conscientiousness', \n",
    "    'Watson Extraversion',\n",
    "    'Watson Agreeableness', \n",
    "    'Watson Emotional Range'\n",
    "]\n",
    "\n",
    "X = train[features]\n",
    "y = train['gilded'].astype(bool)\n",
    "\n",
    "X1 = test[features]\n",
    "y1 = test['gilded'].astype(bool)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                  random_state=None)\n",
    "rscore = 0\n",
    "\n",
    "for i in range(len(features)):\n",
    "    rfe = RFE(estimator=forest, n_features_to_select=(len(features) - i), step=1)\n",
    "    rfe.fit(X,y)\n",
    "    score = rfe.score(X1, y1)\n",
    "    if score > rscore:\n",
    "        rscore = score\n",
    "        rrfe = rfe\n",
    "    \n",
    "i = 0\n",
    "for j in rrfe.ranking_:\n",
    "    if j < 2:\n",
    "        print features[i]\n",
    "    i += 1\n",
    "print\n",
    "print 'Score:', rrfe.score(X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gilded Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[ 'Score BracketWord CountTime of Daywatson clusterbody clusterGrammer ErrorsSentiment NegativeSentiment PositiveSentiment NeutralWatson AngerWatson DisgustWatson FearWatson JoyWatson SadnessWatson TenativeWatson OpennessWatson ConscientiousnessWatson ExtraversionWatson AgreeablenessWatson Emotional Range'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2c62a53e8cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[1;34m'./mytest/added'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msubreddit\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_test.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         'gilded')\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-990f871dd9a3>\u001b[0m in \u001b[0;36mshow_feature_importance\u001b[0;34m(train_filename, test_filename, features, predict)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[1;31m# Print feature importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-5a77ad5cd6ff>\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(train, test, features, predict, trees, state)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jsmoo\\Anaconda2\\envs\\cs489\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2051\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2052\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jsmoo\\Anaconda2\\envs\\cs489\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2093\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jsmoo\\Anaconda2\\envs\\cs489\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[ 'Score BracketWord CountTime of Daywatson clusterbody clusterGrammer ErrorsSentiment NegativeSentiment PositiveSentiment NeutralWatson AngerWatson DisgustWatson FearWatson JoyWatson SadnessWatson TenativeWatson OpennessWatson ConscientiousnessWatson ExtraversionWatson AgreeablenessWatson Emotional Range'] not in index\""
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'Score Bracket',\n",
    "    'Word Count',\n",
    "    'Time of Day',\n",
    "    'watson cluster',\n",
    "    'body cluster',\n",
    "    'Grammer Errors',\n",
    "    'Sentiment Negative',\n",
    "    'Sentiment Positive',\n",
    "    'Sentiment Neutral',\n",
    "    'Watson Anger',\n",
    "    'Watson Disgust',\n",
    "    'Watson Fear',\n",
    "    'Watson Joy',\n",
    "    'Watson Sadness',\n",
    "    'Watson Tenative',\n",
    "    'Watson Openness',\n",
    "    'Watson Conscientiousness',\n",
    "    'Watson Extraversion',\n",
    "    'Watson Agreeableness',\n",
    "    'Watson Emotional Range'\n",
    "]\n",
    "\n",
    "gilded = show_feature_importance('./mytrain/added' + subreddit + '_train.csv', \n",
    "                        './mytest/added' + subreddit + '_test.csv', \n",
    "                        features, \n",
    "                        'gilded')\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"classifiers/\" + subreddit + \"_classifier.pickle\",'wb') as f:\n",
    "    pickle.dump(gilded, f) # saves classifier to file"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs489]",
   "language": "python",
   "name": "conda-env-cs489-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
