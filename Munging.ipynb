{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdviceAnimals_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scripts import Munger as mg\n",
    "\n",
    "badwordspd = pd.read_csv('Terms-to-Block.csv')\n",
    "badwords = badwordspd['Word']\n",
    "\n",
    "filepath = './Start Data/Train/'\n",
    "\n",
    "files2015 = [f for f in os.listdir(filepath)]\n",
    "for f in files2015:\n",
    "    path = filepath+f\n",
    "    print(f)\n",
    "    df = pd.read_csv(path)\n",
    "    df['Contains MD'] = df['body'].apply(lambda x: mg.containsMD(str(x)))\n",
    "    df['Contains tldr'] = df['body'].apply(lambda x: mg.containsTLDR(str(x)))\n",
    "    df['Word Count'] = df['body'].apply(lambda x: mg.wordcount(str(x)))\n",
    "    df['Emoji Count'] =df['body'].apply(lambda x: mg.emojicount(str(x)))\n",
    "    df['Time of Day'] =df['created_utc'].apply(lambda x: mg.getTimeofDay(x))\n",
    "    \n",
    "    df['Score Classified'] = df['score'].apply(lambda x: mg.get_Up_Classification(x))\n",
    "    df['Bad Words'] = df['body'].apply(lambda x: mg.get_listofwordcount(x, badwords))\n",
    "#     df['Sentiment Json'] = df['body'].apply(lambda x: mg.get_sentiment_json(x))\n",
    "#     df['Sentiment Negative'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_neg(x))\n",
    "#     df['Sentiment Positive'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_pos(x))\n",
    "#     df['Sentiment Neutral'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_neutral(x))\n",
    "#     df['Sentiment Label'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_label(x))\n",
    "    df['Grammer Errors'] = df['body'].apply(lambda x: mg.get_grammer_error_count(x))\n",
    "    \n",
    "    \n",
    "    df.to_csv('./mytest/added'+f,index = False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addedAdviceAnimals_train.csv\n",
      "addedAskReddit_train.csv\n",
      "addedfunny_train.csv\n",
      "addednews_train.csv\n",
      "addednfl_train.csv\n",
      "addedpics_train.csv\n",
      "addedtodayilearned_train.csv\n",
      "addedvideos_train.csv\n",
      "addedworldnews_train.csv\n",
      "addedWTF_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scripts import Munger as mg\n",
    "\n",
    "filepath = './mytrain/'\n",
    "\n",
    "files2015 = [f for f in os.listdir(filepath)]\n",
    "for f in files2015:\n",
    "    path = filepath+f\n",
    "    print(f)\n",
    "    df = pd.read_csv(path)\n",
    "    df['Sentiment Json'] = df['body'].apply(lambda x: mg.get_sentiment_json(x))\n",
    "    df['Sentiment Negative'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_neg(x))\n",
    "    df['Sentiment Positive'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_pos(x))\n",
    "    df['Sentiment Neutral'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_neutral(x))\n",
    "    df['Sentiment Label'] = df['Sentiment Json'].apply(lambda x: mg.get_sentiment_label(x))\n",
    "\n",
    "    \n",
    "    \n",
    "    df.to_csv(filepath+f,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addedAdviceAnimals_train.csv\n",
      "(400, 37)\n",
      "addedAskReddit_train.csv\n",
      "(400, 37)\n",
      "addedfunny_train.csv\n",
      "(400, 37)\n",
      "addednews_train.csv\n",
      "(400, 37)\n",
      "addednfl_train.csv\n",
      "(400, 37)\n",
      "addedpics_train.csv\n",
      "(400, 37)\n",
      "addedtodayilearned_train.csv\n",
      "(400, 37)\n",
      "addedvideos_train.csv\n",
      "(400, 37)\n",
      "addedworldnews_train.csv\n",
      "(400, 37)\n",
      "addedWTF_train.csv\n",
      "(400, 37)\n",
      "addedAdviceAnimals_test.csv\n",
      "(400, 37)\n",
      "addedAskReddit_test.csv\n",
      "(400, 37)\n",
      "addedfunny_test.csv\n",
      "(400, 37)\n",
      "addednews_test.csv\n",
      "(400, 37)\n",
      "addednfl_test.csv\n",
      "(400, 37)\n",
      "addedpics_test.csv\n",
      "(400, 37)\n",
      "addedtodayilearned_test.csv\n",
      "(400, 37)\n",
      "addedvideos_test.csv\n",
      "(400, 37)\n",
      "addedworldnews_test.csv\n",
      "(400, 37)\n",
      "addedWTF_test.csv\n",
      "(400, 37)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scripts import Munger as mg\n",
    "\n",
    "filepaths = ['./mytrain/','./mytest/']\n",
    "\n",
    "for filepath in filepaths:\n",
    "    files2015 = [f for f in os.listdir(filepath)]\n",
    "    for f in files2015:\n",
    "        path = filepath+f\n",
    "        print(f)\n",
    "        df = pd.read_csv(path)\n",
    "        print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addedAdviceAnimals_test.csv\n",
      "addedAskReddit_test.csv\n",
      "addedfunny_test.csv\n",
      "addednews_test.csv\n",
      "addednfl_test.csv\n",
      "addedpics_test.csv\n",
      "addedtodayilearned_test.csv\n",
      "addedvideos_test.csv\n",
      "addedworldnews_test.csv\n",
      "addedWTF_test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from scripts import Munger as mg\n",
    "\n",
    "\n",
    "user = '95a7beae-b5b4-4193-9481-8c2cb028580b'\n",
    "password = 'YG2mBFbH1R8G'\n",
    "\n",
    "filepath = './mytest/'\n",
    "\n",
    "files2015 = [f for f in os.listdir(filepath)]\n",
    "for f in files2015:\n",
    "    path = filepath+f\n",
    "#     if f == 'addedvideos_train.csv' or f == 'addedworldnews_train.csv' or f == 'addedWTF_train.csv':\n",
    "    print(f)\n",
    "    df = pd.read_csv(path)\n",
    "    df['Watson Json'] = df['body'].apply(lambda x: mg.get_Wat_json(user, password,str(x.decode(\"ascii\", errors=\"ignore\"))))\n",
    "    df['Watson Anger'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Anger(x))\n",
    "    df['Watson Disgust'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Disgust(x))\n",
    "    df['Watson Fear'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Fear(x))\n",
    "    df['Watson Joy'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Joy(x))\n",
    "    df['Watson Sadness'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Sadness(x))\n",
    "    df['Watson Analytical'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Analytical(x))\n",
    "    df['Watson Confident'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Confident(x))\n",
    "    df['Watson Tenative'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Tentative(x))\n",
    "    df['Watson Openness'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Openness(x))\n",
    "    df['Watson Conscientiousness'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Conscientiousness(x))\n",
    "    df['Watson Extraversion'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Extraversion(x))\n",
    "    df['Watson Agreeableness'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Agreeableness(x))\n",
    "    df['Watson Emotional Range'] = df['Watson Json'].apply(lambda x: mg.get_Wat_Emotional_Range(x))\n",
    "\n",
    "\n",
    "    df.to_csv(filepath+f,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\n",
      "These things are so old. I used to frequent a site called sodaplay way back over 10 years ago that was partially inspired by these things. Fucking reposts Http://www.sodaplay.com\n"
     ]
    }
   ],
   "source": [
    "string = 'These things are so old. I used to frequent a site called sodaplay way back over 10 years ago that was partially inspired by these things. Fucking reposts… Http://www.sodaplay.com'\n",
    "print string[154]\n",
    "print str(string.decode(\"ascii\", errors=\"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addedAdviceAnimals_test.csv\n",
      "414\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scripts import Munger as mg\n",
    "\n",
    "filepath = './mytrain/'\n",
    "\n",
    "files2015 = [f for f in os.listdir(filepath)]\n",
    "for f in files2015:\n",
    "    path = filepath+f\n",
    "    print(f)\n",
    "    df = pd.read_csv(path)\n",
    "    if f == 'addedAdviceAnimals_train.csv' or f == 'addedAdviceAnimals_test.csv':\n",
    "        df['Flair'] = df['author_flair_css_class'].apply(lambda x: mg.AdviceAnimals_flair_number(x))\n",
    "    elif f == 'addednfl_train.csv' or f == 'addednfl_test.csv':\n",
    "        df['Flair'] = df['author_flair_css_class'].apply(lambda x: mg.nfl_flair_number(x))\n",
    "    else:\n",
    "        df['Flair'] = df['author_flair_css_class'].apply(lambda x: mg.other_flair(x))\n",
    "    \n",
    "    \n",
    "    df.to_csv(filepath+f,index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
