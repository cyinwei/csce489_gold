{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddit = 'nfl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts import Munger as mg\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_importance(train, test, features, predict, trees=10, state=None):\n",
    "    \n",
    "    X = train[features]\n",
    "    y = train[predict]\n",
    "\n",
    "    # Build a forest and compute the feature importances\n",
    "    forest = ExtraTreesClassifier(n_estimators=trees,\n",
    "                                  random_state=state)\n",
    "\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print '%d.' % (f + 1), X.columns.values[indices[f]], '(%f)' % importances[indices[f]]\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), [ X.columns.values[i] for i in indices], rotation=75)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "    X = test[features]\n",
    "    y = test[predict]\n",
    "\n",
    "    print 'Score:', forest.score(X,y)\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_vectorize(train, test, maxdf=0.8, mindf=0.05):\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_df=maxdf, min_df=mindf)\n",
    "\n",
    "    train_tfidf = tfidf.fit_transform(train)\n",
    "    test_tfidf = tfidf.transform(test)\n",
    "    \n",
    "    return {'train_tfidf': train_tfidf,'test_tfidf': test_tfidf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "def cluster(train, test, clusters=10, iterations=300, init=10):\n",
    "    km = KMeans(n_clusters=clusters, init='k-means++', max_iter=iterations, n_init=init)\n",
    "    \n",
    "    train_preds = km.fit_predict(train)\n",
    "    test_preds = km.predict(test)\n",
    "    \n",
    "    return {'train_preds': train_preds, 'test_preds': test_preds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_feature_importance(train_filename, test_filename, features, predict):\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(train_filename)\n",
    "    test = pd.read_csv(test_filename)\n",
    "    \n",
    "    \n",
    "    train = train.append(test.head(350))\n",
    "    test = test.tail(50)\n",
    "    \n",
    "    # Munge data\n",
    "    train = mg.munge_dataset(train)\n",
    "    test = mg.munge_dataset(test)\n",
    "    \n",
    "    if 'watson cluster' in features:\n",
    "        # Create Watson Vector\n",
    "        watson = ['Watson Anger', 'Watson Disgust', 'Watson Fear',\n",
    "                   'Watson Joy', 'Watson Sadness', 'Watson Analytical',\n",
    "                   'Watson Confident', 'Watson Tenative', 'Watson Openness',\n",
    "                   'Watson Conscientiousness', 'Watson Extraversion',\n",
    "                   'Watson Agreeableness', 'Watson Emotional Range'] \n",
    "        train_watson_vector = train[watson].values\n",
    "        test_watson_vector = test[watson].values\n",
    "\n",
    "        # Cluster by Watson Vector\n",
    "        preds = cluster(train_watson_vector, test_watson_vector, 12, 300, 10)\n",
    "        train['watson cluster'] = preds['train_preds']\n",
    "        test['watson cluster'] = preds['test_preds']\n",
    "\n",
    "    if 'body cluster' in features:\n",
    "        # Create TFIDF vector for body\n",
    "        tfidf = tfidf_vectorize(train['body'], test['body'], maxdf=0.8, mindf=0.05)\n",
    "        train_tfidf = tfidf['train_tfidf']\n",
    "        test_tfidf = tfidf['test_tfidf']\n",
    "        \n",
    "        # Cluster by Body TFIDF Vector\n",
    "        preds = cluster(train_tfidf, test_tfidf, 35, 300, 10)\n",
    "\n",
    "        train['body cluster'] = preds['train_preds']\n",
    "        test['body cluster'] = preds['test_preds']\n",
    "\n",
    "    # Map gilded to boolean\n",
    "    train['gilded'] = train['gilded'].astype(bool)\n",
    "    test['gilded'] = test['gilded'].astype(bool)\n",
    "    \n",
    "    # Print feature importance\n",
    "    return feature_importance(train, test, features, predict, trees=250, state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Bracket\n",
      "Contains MD\n",
      "Word Count\n",
      "Time of Day\n",
      "watson cluster\n",
      "body cluster\n",
      "Grammer Errors\n",
      "Sentiment Label\n",
      "Sentiment Negative\n",
      "Sentiment Positive\n",
      "Sentiment Neutral\n",
      "flair\n",
      "Watson Anger\n",
      "Watson Disgust\n",
      "Watson Fear\n",
      "Watson Joy\n",
      "Watson Sadness\n",
      "Watson Analytical\n",
      "Watson Confident\n",
      "Watson Tenative\n",
      "Watson Openness\n",
      "Watson Conscientiousness\n",
      "Watson Extraversion\n",
      "Watson Agreeableness\n",
      "Watson Emotional Range\n",
      "\n",
      "Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('./mytrain/added' + subreddit + '_train.csv')\n",
    "test = pd.read_csv('./mytest/added' + subreddit + '_test.csv')\n",
    "\n",
    "train = train.append(test.head(350))\n",
    "test = test.tail(50)\n",
    "\n",
    "train = mg.munge_dataset(train)\n",
    "test = mg.munge_dataset(test)\n",
    "\n",
    "# Create Watson Vector\n",
    "watson = ['Watson Anger', 'Watson Disgust', 'Watson Fear',\n",
    "           'Watson Joy', 'Watson Sadness', 'Watson Analytical',\n",
    "           'Watson Confident', 'Watson Tenative', 'Watson Openness',\n",
    "           'Watson Conscientiousness', 'Watson Extraversion',\n",
    "           'Watson Agreeableness', 'Watson Emotional Range'] \n",
    "train_watson_vector = train[watson].values\n",
    "test_watson_vector = test[watson].values\n",
    "\n",
    "# Cluster by Watson Vector\n",
    "preds = cluster(train_watson_vector, test_watson_vector, 12, 300, 10)\n",
    "train['watson cluster'] = preds['train_preds']\n",
    "test['watson cluster'] = preds['test_preds']\n",
    "\n",
    "# Create TFIDF vector for body\n",
    "tfidf = tfidf_vectorize(train['body'], test['body'], maxdf=0.8, mindf=0.05)\n",
    "train_tfidf = tfidf['train_tfidf']\n",
    "test_tfidf = tfidf['test_tfidf']\n",
    "\n",
    "# Cluster by Body TFIDF Vector\n",
    "preds = cluster(train_tfidf, test_tfidf, 35, 300, 10)\n",
    "\n",
    "train['body cluster'] = preds['train_preds']\n",
    "test['body cluster'] = preds['test_preds']\n",
    "\n",
    "features = [\n",
    "    'Score Bracket', \n",
    "    'Contains MD', \n",
    "    'Word Count', \n",
    "    'Time of Day', \n",
    "    'watson cluster',\n",
    "    'body cluster',\n",
    "    'Grammer Errors',\n",
    "    'Sentiment Label',\n",
    "    'Sentiment Negative',\n",
    "    'Sentiment Positive',\n",
    "    'Sentiment Neutral',\n",
    "    'flair',\n",
    "    'Watson Anger', \n",
    "    'Watson Disgust', \n",
    "    'Watson Fear',\n",
    "    'Watson Joy', \n",
    "    'Watson Sadness', \n",
    "    'Watson Analytical',\n",
    "    'Watson Confident', \n",
    "    'Watson Tenative', \n",
    "    'Watson Openness',\n",
    "    'Watson Conscientiousness', \n",
    "    'Watson Extraversion',\n",
    "    'Watson Agreeableness', \n",
    "    'Watson Emotional Range'\n",
    "]\n",
    "\n",
    "X = train[features]\n",
    "y = train['gilded'].astype(bool)\n",
    "\n",
    "X1 = test[features]\n",
    "y1 = test['gilded'].astype(bool)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                  random_state=None)\n",
    "rscore = 0\n",
    "\n",
    "for i in range(len(features)):\n",
    "    rfe = RFE(estimator=forest, n_features_to_select=(len(features) - i), step=1)\n",
    "    rfe.fit(X,y)\n",
    "    score = rfe.score(X1, y1)\n",
    "    if score > rscore:\n",
    "        rscore = score\n",
    "        rrfe = rfe\n",
    "    \n",
    "i = 0\n",
    "for j in rrfe.ranking_:\n",
    "    if j < 2:\n",
    "        print features[i]\n",
    "    i += 1\n",
    "print\n",
    "print 'Score:', rrfe.score(X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gilded Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Score Bracket',\n",
    "    'Contains MD',\n",
    "    'Word Count',\n",
    "    'Time of Day',\n",
    "    'watson cluster',\n",
    "    'body cluster',\n",
    "    'Grammer Errors',\n",
    "    'Sentiment Label',\n",
    "    'Sentiment Negative',\n",
    "    'Sentiment Positive',\n",
    "    'Sentiment Neutral',\n",
    "    'flair',\n",
    "    'Watson Anger',\n",
    "    'Watson Disgust',\n",
    "    'Watson Fear',\n",
    "    'Watson Joy',\n",
    "    'Watson Sadness',\n",
    "    'Watson Analytical',\n",
    "    'Watson Confident',\n",
    "    'Watson Tenative',\n",
    "    'Watson Openness',\n",
    "    'Watson Conscientiousness',\n",
    "    'Watson Extraversion',\n",
    "    'Watson Agreeableness',\n",
    "    'Watson Emotional Range',\n",
    "]\n",
    "\n",
    "gilded = show_feature_importance('./mytrain/added' + subreddit + '_train.csv', \n",
    "                        './mytest/added' + subreddit + '_test.csv', \n",
    "                        features, \n",
    "                        'gilded')\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"classifiers/\" + subreddit + \"_classifier.pickle\",'wb') as f:\n",
    "    pickle.dump(gilded, f) # saves classifier to file"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs489]",
   "language": "python",
   "name": "conda-env-cs489-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
